{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "import PyPDF2\n",
    "import re\n",
    "from pandas import DataFrame, concat\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output folders\n",
    "INPUT_FOLDER = '/home/jovyan/work/INPUT/'\n",
    "OUTPUT_FOLDER = '/home/jovyan/work/OUTPUT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set PDF filename with initial data\n",
    "filename = INPUT_FOLDER + 'signagnd_2018-10-28.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from PDF\n",
    "pdfReader = PyPDF2.PdfFileReader(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 is parsed successfully\n",
      "page 2 is parsed successfully\n",
      "page 3 is parsed successfully\n",
      "page 4 is parsed successfully\n",
      "page 5 is parsed successfully\n",
      "page 6 is parsed successfully\n",
      "page 7 is parsed successfully\n"
     ]
    }
   ],
   "source": [
    "# read PDF page by page\n",
    "number_of_pages = pdfReader.numPages\n",
    "pages = []\n",
    "page = 7\n",
    "for page in range(number_of_pages):\n",
    "    # get title and date from the page header\n",
    "    text = pdfReader.getPage(page).extractText()\n",
    "    title = re.search('OKLAHOMA(.*) \\(', text[:200]).group(1) or ''\n",
    "    date = re.search('DATE:(.*)TIME:', text).group(1) or ''\n",
    "    date = str(datetime.strptime(date, \"%B %d, %Y\").date())\n",
    "\n",
    "    # parse table data from the same page\n",
    "    original = read_pdf(filename, pages=page)\n",
    "\n",
    "    # remove empty rows\n",
    "    rows = original.fillna(method='ffill')\n",
    "    rows['docket'] = title\n",
    "    rows['date'] = date\n",
    "    rows['type'] = ''\n",
    "    rows['cause_num'] = ''\n",
    "\n",
    "    # split the column 'Cause Number' into 'type' and 'cause_num'\n",
    "    rows['type'], rows['cause_num'] = rows['Cause Number'].str.split(' ', 1).str\n",
    "\n",
    "    # merge the rows\n",
    "    grouped = rows.groupby('cause_num')\n",
    "    rows = grouped.agg({\n",
    "        'docket': 'first',\n",
    "        'date': 'first',\n",
    "        'type': 'first',\n",
    "        'cause_num': 'first',\n",
    "        'Applicant/Respondent/Staff Att.': 'first',\n",
    "        'Order Descript/Relief/Title': '\\n'.join,\n",
    "        'County': 'first',\n",
    "        'Pro.': 'first'})\n",
    "\n",
    "    # rename the columns\n",
    "    rows = rows.rename(columns={'Applicant/Respondent/Staff Att.': 'applicant',\n",
    "                                'Order Descript/Relief/Title': 'order_descr',\n",
    "                                'County': 'county',\n",
    "                                'Pro.': 'pro'})\n",
    "\n",
    "    # check description if exists, or fill with empty cell\n",
    "    rows['order_desc_1'] = rows['order_descr'].str.split('\\n').str[0]\n",
    "    rows['order_desc_2'] = rows['order_descr'].str.split('\\n').str[1]\n",
    "    rows['order_desc_3'] = rows['order_descr'].str.split('\\n').str[2]\n",
    "    rows['order_desc_4'] = rows['order_descr'].str.split('\\n').str[3]\n",
    "    rows['order_desc_5'] = rows['order_descr'].str.split('\\n').str[4]\n",
    "    rows['order_desc_6'] = rows['order_descr'].str.split('\\n').str[5]\n",
    "\n",
    "    # remove empty cells\n",
    "    rows = rows.fillna('')\n",
    "\n",
    "    pages.append(rows)\n",
    "\n",
    "    print('page {} is parsed successfully'.format(page + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all pages\n",
    "result = concat(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result to CSV file\n",
    "result.to_csv(OUTPUT_FOLDER + 'result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save SQL queries to file\n",
    "openFile = open(OUTPUT_FOLDER + 'result.csv', 'r')\n",
    "csvFile = csv.reader(openFile)\n",
    "header = next(csvFile)\n",
    "headers = map((lambda x: '`' + x + '`'), header)\n",
    "insert = 'INSERT INTO Table (' + \", \".join(headers) + \") VALUES \"\n",
    "\n",
    "sql_queries = []\n",
    "for row in csvFile:\n",
    "    values = map((lambda x: '\"'+x+'\"'), row)\n",
    "    sql_query = insert + \"(\" + \", \".join(values) + \");\"\n",
    "    sql_queries.append(sql_query)\n",
    "\n",
    "openFile.close()\n",
    "\n",
    "with open(OUTPUT_FOLDER + 'result.sql', 'w') as f:\n",
    "    for sql_query in sql_queries:\n",
    "        f.write(\"%s\\n\" % sql_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
